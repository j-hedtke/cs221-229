In this section we demonstrate the workflow by training and testing a model for salt body interpretation
The seismic image in this example is cropped from SEAM Phase  synthetic dataset
We selected  crossline D slices as training data
The training labels are manual annotations generated by an optimal path picking method
With a seismic amplitude image as input the network should identify the entire salt body as a probability map output starting from a seed point  We set the FoV size for D salt body interpretation to x 
Although it is a relatively small size compared to x the size of the target the movement of the FoV should be able to cover the entirety of the salt body
In the network we downsample the inputs  times with x max pooling every  convolutional layers  in the encoder section and symmetrically upsample in the decoder section
Since the dimension of the inputs is downsampled x in total before upsampling the FoV is zeropadded to x and cropped to the original size at the final output  In order to train the model to move the FoV effectively within the geobody we adopt a dynamic subregion scheme to constrain the movements of the FoV during training
A limited number of subregions are randomly sampled from each training image so that all subregions are centered within the valid geobody
In the first epoch subregions share the same size with the FoV so the network only learns how to segment the input image without actually moving the FoV
After that the subregions grow in size until hitting the x limit on each new epoch
This way the network gradually learns to move the FoV based on previous segmentation results further and further away from the starting point
We train the model for  epochs and use area under the curve   as the metric to determine the matching performance of the prediction likelihood against the ground truth  The training took less than  hours with a GTX Ti GPU
Note that because the FoV cannot move outside the image boundary FoV centers could not cover the entire range of the picked fault however the segmentation of that fault is already completed and floodfilling can continue as shown in Figure   Figure  show examples of picking only one fault instance with other faults in the vicinity
Figure  shows tracking history when the seed point is put on the middle fault and in Figure  the floodfilling can continue to fill up the entire instance
Figure  show similar processes but start with different seed points to the left and right side of the one in Figure 
In Figure  even though the seed point is slightly off from the correct fault position floodfilling can automatically correct to align with the fault
Note that although the tracking is focused on one of the many faults the output fault likelihood maps overlaid on the background image show that the model is still aware of the other faults in the vicinity depending on the size of the FoV
Figure  shows all three fault instances generated in Figure 
This demonstrates the ability to separate geobody instances with the same attribute  Although all examples are in D the transfer of this concept to D is straightforward and requires trivial effort
In D the proposed workflow can be more computationally efficient than the traditional sliding window scheme
In addition to the salt body and fault interpretation the proposed method can be additionally suitable for D channel tracking  On the other hand the proposed method may not perform well in the case of trying to separate instances that overlap
This is due to the fact that each FoV search for the proposal for the next movement in all directions equally in order to fill the geobody space
However show that deep learning can predict not only geobody likelihood but also relevant attributes  fault dip and strike angle
It is worth investigating to utilize these important directional attributes in deep learning interpretation methods such as guiding the floodfilling search pattern so that overlapping instances can be separated
Figure  shows the predicted results after implementing prediction on the whole dataset by using trained model  From Figure  high accuracy can be seen on the sections used for training and sections in the neighborhood
Both positions and boundaries of seismic facies are generally predicted correctly
It is obvious that prediction on training sections such as inline  achieves high similarity to label images although some tiny details need better prediction  Several seismic facies are predicted particularly precisely in Figure  for example high amplitude continuous  grizzly  high amplitude  and salt dome
It takes  hours  minutes in training and only   seconds in onesection prediction on two NVIDIA Tesla Km GPUs  Compared with CNNs applied for seismic facies interpretation  our scheme significantly reduces computational time in training and predicting
Meanwhile seismic facies are classified more accurately by DeepLabv
Compared with simple encoderdecoder models in seismic facies interpretation  our scheme predicts more accurate results for encoding multiscale information and decoding more details  Good performance can be observed even in crossline sections timeslice sections and the inline sections far from training sections as shown in Figure 
These predicted sections are randomly extracted from the predicted data cube  And note that the size of each training slice is Ud while data sections to be predicted are at size Ud
It means that DeepLabv is flexible in size during training and predicting  We propose an effective scheme for automatic seismic facies interpretation by utilizing DeepLabv
This enhanced encoderdecoder structure produces more accurate pixellevel predictions by extracting multiscale features and recovering more details
And this scheme reduces weights to significantly improve efficiency
The implementation on F dataset shows its good performance in seismic facies interpretation
Furthermore the well predicted results indicate huge potentials in seismic interpretation using DeepLabv
Seismic facies commonly indicate types of lithological association and sedimentary characteristics of geological bodies
The interpretation of seismic facies provides a reference for analyzing subsurface geological conditions
Conventional seismic interpretation methods usually require a lot of manual works and the interpretation results are inevitably affected by some subjective factors
To address these issues deep learning has drawn a lot of attention in recent years  Research in deep learning has made significant progress in several fields such as computer vision
Considering the similarity between seismic interpretation and computer vision many researchers adopt computer vision algorithms to analyze and understand subsurface structures
Convolutional neural networks   are commonly considered to solve seismic interpretation problems such as faults identification  salt dome prediction  and seismic facies interpretation
However CNN has a fatal shortage that CNN merely predicts imagewise classification results instead of pixelwise results
Although dense prediction can be achieved by performing classification using CNN models on small patches of data to infer the class label at the patch center  it is inaccurate and computationally timeconsuming  The FCN model  developed from CNN inspires researchers to establish encoderdecoder structures for semantic segmentation tasks
These structures are specially designed for dense predictions because they can predict pixellevel outputs in real time
The encoder similar to a CNN model is used to extract features to obtain feature maps and the decoder similar to a deconvolution operation is used to recover feature maps to the original size and predict outputs
Simple encoderdecoder models have been implemented in salt dome detection  and facies interpretation   DeepLabv  is an enhanced encoderdecoder structure that achieves a stateoftheart performance on PASCAL VOC  and Cityscapes datasets
This structure performs higher accuracy than simple encoderdecoder models by applying Atrous spatial pyramid pooling  module and a simple yet effective decoder module
By utilizing depthwise separable convolution DeepLabv can reduce a lot of weights and greatly improve the efficiency
In this paper we propose a scheme for seismic facies interpretation using DeepLabv  After implementing effective data augmentation to generate diversity training samples we perform DeepLabv to extract multiscale features of seismic facies and recover more details in prediction results
By tuning parameters the application of our scheme on F dataset demonstrates good performance for high accuracy and efficiency After data augmentation we obtain thousands of diversity data slices at crop size Ud or Ud
All data slices are set as training data and the  training sections without being cropped are set as evaluation data
Test data and data for predicting are also complete seismic sections without being cropped in slices
We test several sets of parameters including base learning rate data crop size atrous rates in ASPP module output stride and number of data slices for training after data augmentation
These parameters may affect prediction for training the encoderdecoder structure  The performance is measured by mean intersection over union   across the  facies  Higher value of mIoU represents better performance
The details and quantitative comparison results are listed in Table   By comprehensive comparison of prediction results under different parameters a set of parameters for performing best both in accuracy and efficiency are selected as the final scheme
We train  data slices on DeepLabv with base learning rate    data crop size   and atrous rates     with output stride  
In  we proposed a method for automatically obtaining large amounts of weaklylabeled data using two main steps similaritybased retrieval and weaklysupervised label mapping
The only requirement is for the interpreter to define the various classes by selecting at least one exemplar image for every class
Due to the limited space we provide a brief explanation only and we refer to our previous work for the details  Similaritybased retrieval takes exemplar images for each seismic facies like the ones shown in Figure  and then retrieves thousands of images with similar facies to the exemplar images  In our work two exemplar images for every class were sufficient
Figure  shows the exemplar images for different facies  from our recently released dataset  and shows a small subset of the retrieved images for every class
In this work we retrieve  images for every class of seismic facies  Given the retrieved images the weaklysupervised label mapping algorithm learns the common features in each class and then uses these common features to predict the pixellevel labels for all the retrieved images
Figure  shows the label mapping results for various images
The label mapping algorithm also produces confidence values denoted q in each label it predicts
In the next subsection we explain how these confidence values are used in the network loss function of our weaklysupervised models To train and test our different models we use our recently released facies classification dataset
This dataset includes six different lithostratigraphic classes from the Netherlands F block
There are  the Upper Middle and Lower North Sea groups in addition to the RijnlandChalk Scruff and Zechstein groups
Figure  shows a D view of the survey with the Scruff and Zechstein groups visible
We use  patches extracted from the NW region of the survey for training and we test our models on test set  and  as shown in Figure   For a fair comparison between strongly and weaklysupervised models we use the same underlying architecture for both
We use an encoderdecoder style architecture similar to SegNet 
This architecture performs well for semantic segmentation tasks and outputs a prediction that matches the size of the network input
In our case the output predictions are six  patches corresponding the six different classes in our dataset
In addition to the baseline case we also test the same models with data augmentation and skip connections
We use  of our training data for validation and we train all our models until convergence
We then apply these models on the two test sets in a sliding window fashion and average the resulting heat maps for the six classes
Finally we compute our evaluation metrics on both test sets and report the results in Table   We use several metrics to evaluate our models
Namely pixel accuracy  class accuracy  for each individual class mean class accuracy  which averages the CA score for all classes and frequencyweighted intersection over union   These metrics are detailed in   Figure  shows sample results from inline  in test set  for both our strongly and weaklysupervised models
Also Table  summarizes the objective results that we have obtained  In the stronglysupervised model adding skip connections and augmentation to the baseline both helped improve the results over the baseline model
We note that in Figure  the stronglysupervised results are rather good except for the two models This involves randomly rotating every training patch by up to adding random Gaussian noise and randomly flipping the training patches horizontally  confusing the features in the Scruff class with the ones in the Upper North Sea class
Sectionbased models that train on the entire section not only patches can help remedy this issue  On the other hand our preliminary weaklysupervised results show that using data augmentation and increasing the value of g to let the network focus on harder misclassified regions can help improve the results
Furthermore when we weigh the loss function of each image by its similarity to the exemplar image used to retrieve it  we can also improve the PA and FWIU scores by about 
There are several ways where these weaklysupervised results can be improved this includes the use of more data augmentation during training and testing adding regularization to the network to prevent it from overfitting to the weak labels and better exploitation of side information such as confidence and similarity values
Finally we note that our weaklysupervised results are still preliminary ones and better weaklysupervised results will be shared in the presentation
We use the recently released facies classification benchmark to train and test various strongly and weaklysupervised models for facies classification
We compare the results and these models to study the practicality of using weaklysupervised models for facies classification
The weaklysupervised models only require two images annotated on the imagelevel compared to our stronglysupervised models that used  fullyannotated seismic inlines for training
Naturally the stronglysupervised models perform better than weaklysupervised ones  While our weaklysupervised results are encouraging given the minimal amount of annotated data they require we still believe more research is needed to help minimize the performance gap between weakly and stronglysupervised models
For both models we experiment with using data augmentation to artificially increase the size of the training set  Data augmentation applies different labelpreserving transformations to the training data such as rotation random horizontal flipping and the addition of Gaussian noise 
