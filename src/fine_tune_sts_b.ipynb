{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fine-tune-sts-b.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4Unkw2LxuAJ",
        "colab_type": "code",
        "outputId": "1727f3c6-4534-4029-a6cd-c118c36bad63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "source": [
        "!pip install pytorch_pretrained_bert\n",
        "!pip install transformers \n",
        "\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "#from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification, BertForNextSentencePrediction\n",
        "from transformers import BertModel, BertTokenizer, BertPreTrainedModel, BertForMaskedLM\n",
        "from tqdm import tqdm, trange\n",
        "import io\n",
        "import os\n",
        "import numpy as np\n",
        "import os\n",
        "from glob import glob\n",
        "import json\n",
        "import subprocess\n",
        "import pathlib \n",
        "from google.cloud import storage\n",
        "import uuid\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "\n",
        "!gcloud config set project 'experiments-260319'\n",
        "\n",
        "DATA_BUCKET = 'gs://cs229-project-data'\n",
        "WORK_DIR = '/content'\n",
        "pathlib.Path('/content/data/sts-b').mkdir(parents=True, exist_ok=True)\n",
        "pathlib.Path('/content/output/sts-b').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "DATA_DIR = os.path.join(WORK_DIR, 'data/sts-b/cs229-project-data')\n",
        "OUTPUT_DIR = os.path.join(WORK_DIR, 'output')\n",
        "EXEC_PATH = os.path.join(WORK_DIR, 'src/bert_finetune_with_pytorch.py')\n",
        "\n",
        "#dirname = os.path.dirname(os.path.dirname(__file__))\n",
        "\n",
        "#model_save_path = 'gs://gridspace-tts-data'\n",
        "model_save_path = os.path.join(OUTPUT_DIR, 'sts-b')\n",
        "train_data_path = os.path.join(DATA_DIR, 'sts-train.csv')\n",
        "test_data_path = os.path.join(DATA_DIR, 'sts-test.csv')\n",
        "\n",
        "!gsutil cp -r {DATA_BUCKET} {DATA_DIR}\n",
        "\n",
        "MAX_LEN = 128\n",
        "batch_size = 32\n",
        "\n",
        "learning_rate = 3e-5\n",
        "epochs = 3\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.21.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.9)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.17.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.10.32)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.28.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.32 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.13.32)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.2.1)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->pytorch_pretrained_bert) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->pytorch_pretrained_bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.32->boto3->pytorch_pretrained_bert) (1.12.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.83)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.35)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.32)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.32 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.32)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.32->boto3->transformers) (0.15.2)\n",
            "Updated property [core/project].\n",
            "Copying gs://cs229-project-data/LICENSE.txt...\n",
            "Copying gs://cs229-project-data/correlation.pl...\n",
            "Copying gs://cs229-project-data/readme.txt...\n",
            "Copying gs://cs229-project-data/sts-dev.csv...\n",
            "- [4 files][264.1 KiB/264.1 KiB]                                                \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying gs://cs229-project-data/sts-test.csv...\n",
            "Copying gs://cs229-project-data/sts-train.csv...\n",
            "\\ [6 files][  1.4 MiB/  1.4 MiB]                                                \n",
            "Operation completed over 6 objects/1.4 MiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnZcdMog2OCa",
        "colab_type": "code",
        "outputId": "899ddd50-de7f-401c-adab-796d29e2946f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB3NEbcQze1x",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5HlNkzAzjZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "\n",
        "class BertSimilarity(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super(BertSimilarity, self).__init__(config)\n",
        "        self.bert = BertModel(config)\n",
        "        self.linear = torch.nn.Linear(config.hidden_size, 1)\n",
        "        self.dropout = torch.nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None):\n",
        "\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(pooled_output)\n",
        "        output = self.sigmoid(linear_output)\n",
        "\n",
        "        return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4bPo-aczu4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "\n",
        "    \n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "    if device_name != '/device:GPU:0':\n",
        "      raise SystemError('GPU device not found')\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    n_gpu = torch.cuda.device_count()\n",
        "    torch.cuda.get_device_name(0)\n",
        "\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "    #model.cuda()\n",
        "    scores_train =[]\n",
        "    first_sent_train = []\n",
        "    second_sent_train = []\n",
        "\n",
        "    scores_test =[]\n",
        "    first_sent_test = []\n",
        "    second_sent_test = []\n",
        "\n",
        "    sent_pairs = []\n",
        "\n",
        "    with open(train_data_path, encoding='utf-8') as fin:\n",
        "        train_data = fin.read().split('\\n')\n",
        "    train_data = [line for line in train_data if line.strip()]\n",
        "    for line in train_data:\n",
        "        pair = []\n",
        "        line1 = line.split('\\t')\n",
        "        if float(line1[4]) <= 4.0:\n",
        "            scores_train.append(0)\n",
        "        else:\n",
        "            scores_train.append(1)\n",
        "        first_sent_train.append(line1[5])\n",
        "        second_sent_train.append(line1[6])\n",
        "        pair.append(str(line1[5]))\n",
        "        pair.append(str(line1[6]))\n",
        "        sent_pairs.append(pair)\n",
        "\n",
        "\n",
        "    with open(test_data_path, encoding='utf-8') as fin:\n",
        "        test_data = fin.read().split('\\n')\n",
        "    test_data = [line for line in test_data if line.strip()]\n",
        "    for line in test_data:\n",
        "        line1 = line.split('\\t')\n",
        "        if float(line1[4]) <= 4.0:\n",
        "            scores_test.append(0)\n",
        "        else:\n",
        "            scores_test.append(1)\n",
        "        first_sent_test.append(line1[5])\n",
        "        second_sent_test.append(line1[6])\n",
        "\n",
        "    pairs_train = []\n",
        "    pairs_test = []\n",
        "    segment_ids_train = []\n",
        "    segment_ids_test = []\n",
        "    tokenized_pairs_train = []\n",
        "    tokenized_pairs_test = []\n",
        "\n",
        "    for sent1, sent2 in zip(first_sent_train, second_sent_train):\n",
        "        token1 = tokenizer.tokenize(sent1)\n",
        "        token2 = tokenizer.tokenize(sent2)\n",
        "        pair_tokens = []\n",
        "        pair_segment_ids = []\n",
        "        pair_tokens.append(\"[CLS] \")\n",
        "        pair_segment_ids.append(0)\n",
        "        for t in token1:\n",
        "            pair_tokens.append(t)\n",
        "            pair_segment_ids.append(0)\n",
        "        pair_tokens.append('[SEP]')\n",
        "        for t in token2:\n",
        "            pair_tokens.append(t)\n",
        "            pair_segment_ids.append(1)\n",
        "        pair_tokens.append('[SEP]')\n",
        "        pair_segment_ids.append(1)\n",
        "        tokenized_pairs_train.append(pair_tokens)\n",
        "        segment_ids_train.append(pair_segment_ids)\n",
        "\n",
        "    for sent1, sent2 in zip(first_sent_test, second_sent_test):\n",
        "        token1 = tokenizer.tokenize(sent1)\n",
        "        token2 = tokenizer.tokenize(sent2)\n",
        "        pair_tokens = []\n",
        "        pair_segment_ids = []\n",
        "        pair_tokens.append(\"[CLS] \")\n",
        "        pair_segment_ids.append(0)\n",
        "        for t in token1:\n",
        "            pair_tokens.append(t)\n",
        "            pair_segment_ids.append(0)\n",
        "        pair_tokens.append('[SEP]')\n",
        "        for t in token2:\n",
        "            pair_tokens.append(t)\n",
        "            pair_segment_ids.append(1)\n",
        "        pair_tokens.append('[SEP]')\n",
        "        pair_segment_ids.append(1)\n",
        "        tokenized_pairs_test.append(pair_tokens)\n",
        "        segment_ids_test.append(pair_segment_ids)\n",
        "\n",
        "    print(\"the first tokenized pair:\")\n",
        "    print(tokenized_pairs_train[0])\n",
        "    print(\"the first segment ids:\")\n",
        "    print(segment_ids_train[0])\n",
        "\n",
        "    input_ids_train = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_pairs_train]\n",
        "    input_ids_train = pad_sequences(input_ids_train, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "    input_ids_test = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_pairs_test]\n",
        "    input_ids_test = pad_sequences(input_ids_test, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "    segment_ids_train = pad_sequences(segment_ids_train, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "    segment_ids_test = pad_sequences(segment_ids_test, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "    #encoded = [tokenizer.encode(s, add_special_tokens=True) for s in sent_pairs]\n",
        "    #input_ids2 = torch.tensor([tokenizer.encode(s, add_special_tokens=True) for s in sent_pairs]).unsqueeze(0)\n",
        "\n",
        "    attention_masks_train = []\n",
        "    attention_masks_test = []\n",
        "\n",
        "    # Create a mask of 1s for each token followed by 0s for padding\n",
        "    for seq in input_ids_train:\n",
        "        seq_mask = [float(i > 0) for i in seq]\n",
        "        attention_masks_train.append(seq_mask)\n",
        "    for seq in input_ids_test:\n",
        "        seq_mask = [float(i > 0) for i in seq]\n",
        "        attention_masks_test.append(seq_mask)\n",
        "\n",
        "    # Convert all of our data into torch tensors, the required datatype for our model\n",
        "\n",
        "    train_inputs = torch.tensor(input_ids_train).to(torch.int64)\n",
        "    validation_inputs = torch.tensor(input_ids_test).to(torch.int64)\n",
        "    train_labels = torch.tensor(scores_train).float()\n",
        "    print(train_labels[:100])\n",
        "    validation_labels = torch.tensor(scores_test).float()\n",
        "    train_masks = torch.tensor(attention_masks_train).to(torch.int64)\n",
        "    validation_masks = torch.tensor(attention_masks_test).to(torch.int64)\n",
        "    segment_ids_train = torch.tensor(segment_ids_train).to(torch.int64)\n",
        "    segment_ids_test = torch.tensor(segment_ids_test).to(torch.int64)\n",
        "\n",
        "    # Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop,\n",
        "    # with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "    train_data = TensorDataset(train_inputs, train_masks, train_labels, segment_ids_train)\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "    validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels, segment_ids_test)\n",
        "    validation_sampler = SequentialSampler(validation_data)\n",
        "    validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "    #BertPreTrainedModel = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "\n",
        "    model = BertSimilarity.from_pretrained('bert-base-uncased')\n",
        "    model = model.cuda()\n",
        "\n",
        "    # Set our model to training mode (as opposed to evaluation mode)\n",
        "    model.train()\n",
        "\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "        ]\n",
        "    optimizer = BertAdam(optimizer_grouped_parameters, lr=learning_rate, warmup=.1)\n",
        "\n",
        "\n",
        "\n",
        "    # Store our loss and accuracy for plotting\n",
        "    train_loss_set = []\n",
        "    accuracy = {}\n",
        "\n",
        "    # trange is a tqdm wrapper around the normal python range\n",
        "    for _ in trange(epochs, desc=\"Epoch\"):\n",
        "\n",
        "        # Training\n",
        "\n",
        "        # Tracking variables\n",
        "        tr_loss = 0\n",
        "        nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "        # Train the data for one epoch\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            # Add batch to GPU\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            # Unpack the inputs from our dataloader\n",
        "            b_input_ids, b_input_mask, b_labels, b_segment_ids = batch\n",
        "            # Clear out the gradients (by default they accumulate)\n",
        "            optimizer.zero_grad()\n",
        "            # Forward pass\n",
        "            probs = model(b_input_ids, attention_mask=b_input_mask, token_type_ids=b_segment_ids)\n",
        "            loss_func = torch.nn.BCELoss()\n",
        "            batch_loss = loss_func(probs, b_labels)\n",
        "\n",
        "            train_loss_set.append(batch_loss)\n",
        "            # Backward pass\n",
        "            batch_loss.backward()\n",
        "            # Update parameters and take a step using the computed gradient\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update tracking variables\n",
        "            tr_loss += batch_loss\n",
        "            nb_tr_examples += b_input_ids.size(0)\n",
        "            nb_tr_steps += 1\n",
        "\n",
        "        print(\"Train loss: {}\".format(tr_loss / nb_tr_steps))\n",
        "        \n",
        "        accuracy['train_loss'] = tr_loss / nb_tr_steps\n",
        "       \n",
        "        # Validation\n",
        "\n",
        "        # Put model in evaluation mode to evaluate loss on the validation set\n",
        "        model.eval()\n",
        "\n",
        "        # Tracking variables\n",
        "        eval_loss, eval_accuracy = 0, 0\n",
        "        nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "        train_loss, train_accuracy = 0, 0\n",
        "        nb_train_steps, nb_train_examples = 0, 0\n",
        "\n",
        "        # Evaluate data for one epoch\n",
        "        for batch in validation_dataloader:\n",
        "            # Add batch to GPU\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            # Unpack the inputs from our dataloader\n",
        "            b_input_ids, b_input_mask, b_labels, b_segment_ids = batch\n",
        "            # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "            with torch.no_grad():\n",
        "                # Forward pass, calculate logit predictions\n",
        "                sigmoid = model(b_input_ids, attention_mask=b_input_mask, token_type_ids=b_segment_ids)\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            sigmoid = sigmoid.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            tmp_eval_accuracy = flat_accuracy(sigmoid, label_ids)\n",
        "\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "            nb_eval_steps += 1\n",
        "        \n",
        "        for batch in train_dataloader:\n",
        "            # Add batch to GPU\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            # Unpack the inputs from our dataloader\n",
        "            b_input_ids, b_input_mask, b_labels, b_segment_ids = batch\n",
        "            # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "            with torch.no_grad():\n",
        "                # Forward pass, calculate logit predictions\n",
        "                sigmoid = model(b_input_ids, attention_mask=b_input_mask, token_type_ids=b_segment_ids)\n",
        "\n",
        "            # Move logits and labels to CPU\n",
        "            sigmoid = sigmoid.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "            tmp_train_accuracy = flat_accuracy(sigmoid, label_ids)\n",
        "\n",
        "            train_accuracy += tmp_train_accuracy\n",
        "            nb_train_steps += 1\n",
        "        \n",
        "        accuracy['valid_loss'] = eval_accuracy / nb_eval_steps\n",
        "        \n",
        "        print(\"Validation Accuracy: {}\".format(eval_accuracy / nb_eval_steps))\n",
        "        print(\"Train Accuracy: {}\".format(train_accuracy / nb_train_steps))\n",
        "\n",
        "    print(\"Saving to output folder\")\n",
        "    \n",
        "    acc_filename = os.path.join(model_save_path, 'accuracy.pth')\n",
        "    with open(acc_filename, 'wb') as f:\n",
        "        torch.save(accuracy, f)\n",
        "    f.close()\n",
        "    \n",
        "    train_loss_filename = os.path.join(model_save_path, 'trainloss.pth')\n",
        "    with open(train_loss_filename, 'wb') as f:\n",
        "        torch.save(train_loss_set, f)\n",
        "\n",
        "\n",
        "    model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "    model_to_save.save_pretrained(model_save_path)\n",
        "    tokenizer.save_pretrained(model_save_path)\n",
        "    \n",
        "    #storage_client = storage.Client()\n",
        "    bucket_name = 'gs://cs229-models' + str(uuid.uuid1())\n",
        "    #bucket = storage_client.get_bucket(bucket_name)\n",
        "    !gsutil mb {bucket_name}\n",
        "    !gsutil cp -r {model_save_path} {bucket_name}\n",
        "    \n",
        "    #cp_to_bucket_cmd = 'cp {} {}'.format(model_save_path, bucket_name)\n",
        "\n",
        "    #subprocess.check_call(cp_to_bucket_cmd, shell=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99UFd8dq3JGD",
        "colab_type": "code",
        "outputId": "9e4c428a-83fd-485d-9203-04bbe867d67d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "the first tokenized pair:\n",
            "['[CLS] ', 'a', 'plane', 'is', 'taking', 'off', '.', '[SEP]', 'an', 'air', 'plane', 'is', 'taking', 'off', '.', '[SEP]']\n",
            "the first segment ids:\n",
            "[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "tensor([1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0.,\n",
            "        0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
            "        1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
            "        0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
            "        0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:00<00:00, 169614.62B/s]\n",
            "100%|██████████| 440473133/440473133 [00:37<00:00, 11604730.86B/s]\n",
            "t_total value of -1 results in schedule not being applied\n",
            "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([21])) that is different to the input size (torch.Size([21, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.48385995626449585\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  33%|███▎      | 1/3 [03:30<07:00, 210.39s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8359375\n",
            "Train Accuracy: 0.8169973544973544\n",
            "Train loss: 0.4790232479572296\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  67%|██████▋   | 2/3 [06:57<03:29, 209.33s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8359375\n",
            "Train Accuracy: 0.8171792328042328\n",
            "Train loss: 0.45946332812309265\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch: 100%|██████████| 3/3 [10:23<00:00, 208.47s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8359375\n",
            "Train Accuracy: 0.8170882936507937\n",
            "Saving to output folder\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Creating gs://cs229-modelsaeb377e2-1be1-11ea-9888-0242ac1c0002/...\n",
            "Copying file:///content/output/sts-b/pytorch_model.bin [Content-Type=application/octet-stream]...\n",
            "==> NOTE: You are uploading one or more large file(s), which would run\n",
            "significantly faster if you enable parallel composite uploads. This\n",
            "feature can be enabled by editing the\n",
            "\"parallel_composite_upload_threshold\" value in your .boto\n",
            "configuration file. However, note that if you do this large files will\n",
            "be uploaded as `composite objects\n",
            "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
            "means that any user who downloads such objects will need to have a\n",
            "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
            "without a compiled crcmod, computing checksums on composite objects is\n",
            "so slow that gsutil disables downloads of composite objects.\n",
            "\n",
            "Copying file:///content/output/sts-b/config.json [Content-Type=application/json]...\n",
            "Copying file:///content/output/sts-b/trainloss.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/output/sts-b/added_tokens.json [Content-Type=application/json]...\n",
            "| [4 files][417.8 MiB/417.8 MiB]   40.7 KiB/s                                   \n",
            "==> NOTE: You are performing a sequence of gsutil operations that may\n",
            "run significantly faster if you instead use gsutil -m cp ... Please\n",
            "see the -m section under \"gsutil help options\" for further information\n",
            "about when gsutil -m can be advantageous.\n",
            "\n",
            "Copying file:///content/output/sts-b/vocab.txt [Content-Type=text/plain]...\n",
            "Copying file:///content/output/sts-b/accuracy.pth [Content-Type=application/octet-stream]...\n",
            "Copying file:///content/output/sts-b/tokenizer_config.json [Content-Type=application/json]...\n",
            "Copying file:///content/output/sts-b/special_tokens_map.json [Content-Type=application/json]...\n",
            "- [8 files][418.0 MiB/418.0 MiB]   72.7 KiB/s                                   \n",
            "Operation completed over 8 objects/418.0 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}